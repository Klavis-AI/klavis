{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/klavis-ai/klavis/blob/main/examples/gemini/Use_Klavis_with_Gemini.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Gemini + Klavis AI Integration\n",
        "\n",
        "This tutorial demonstrates how to use Google's Gemini with function calling with Klavis MCP (Model Context Protocol) servers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Prerequisites\n",
        "\n",
        "- **Gemini API key** - Get at [ai.google.dev](https://ai.google.dev/)\n",
        "- **Klavis API key** - Get at [klavis.ai](https://klavis.ai/)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install the required packages\n",
        "%pip install -qU google-generativeai klavis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/zihaolin/src/klavis/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import webbrowser\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "from klavis import Klavis\n",
        "from klavis.types import McpServerName, ConnectionType, ToolFormat\n",
        "\n",
        "# Set environment variables (you can also use .env file)\n",
        "os.environ[\"GEMINI_API_KEY\"] = \"YOUR_GEMINI_API_KEY\"  # Replace with your actual Gemini API key\n",
        "os.environ[\"KLAVIS_API_KEY\"] = \"YOUR_KLAVIS_API_KEY\"  # Replace with your actual Klavis API key\n",
        "\n",
        "# Initialize clients\n",
        "gemini_client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
        "klavis_client = Klavis(api_key=os.getenv(\"KLAVIS_API_KEY\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Case Study 1 : Gemini + YouTube MCP Server\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "#### Step 1 - Create YouTube MCP Server using Klavis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "youtube_mcp_instance = klavis_client.mcp_server.create_server_instance(\n",
        "    server_name=McpServerName.YOUTUBE,\n",
        "    user_id=\"1234\",\n",
        "    platform_name=\"Klavis\",\n",
        "    connection_type=ConnectionType.STREAMABLE_HTTP,\n",
        ")\n",
        "\n",
        "print(f\"üîó YouTube MCP server created at: {youtube_mcp_instance.server_url}, and the instance id is {youtube_mcp_instance.instance_id}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "#### Step 2 - Create general method to use MCP Server with Gemini\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def gemini_with_mcp_server(mcp_server_url: str, user_query: str):\n",
        "    # Get tools from MCP server\n",
        "    mcp_server_tools = klavis_client.mcp_server.list_tools(\n",
        "        server_url=mcp_server_url,\n",
        "        connection_type=ConnectionType.STREAMABLE_HTTP,\n",
        "        format=ToolFormat.GEMINI,\n",
        "    )\n",
        "    print(f\"üì¶ Available tools: {mcp_server_tools}\")\n",
        "    \n",
        "    # Prepare conversation contents\n",
        "    contents = [types.Content(role=\"user\", parts=[types.Part(text=user_query)])]\n",
        "    \n",
        "    # Generate response with function calling\n",
        "    response = gemini_client.models.generate_content(\n",
        "        model='gemini-1.5-pro',\n",
        "        contents=contents,\n",
        "        config=types.GenerateContentConfig(tools=mcp_server_tools.tools)\n",
        "    )\n",
        "    \n",
        "    if response.candidates and response.candidates[0].content.parts:\n",
        "        contents.append(response.candidates[0].content)\n",
        "        \n",
        "        # Check if there are function calls to execute\n",
        "        has_function_calls = False\n",
        "        for part in response.candidates[0].content.parts:\n",
        "            if hasattr(part, 'function_call') and part.function_call:\n",
        "                has_function_calls = True\n",
        "                print(f\"üîß Calling function: {part.function_call.name}\")\n",
        "                \n",
        "                try:\n",
        "                    # Execute tool call via Klavis\n",
        "                    function_result = klavis_client.mcp_server.call_tools(\n",
        "                        server_url=mcp_server_url,\n",
        "                        tool_name=part.function_call.name,\n",
        "                        tool_args=dict(part.function_call.args),\n",
        "                    )\n",
        "                    \n",
        "                    # Create function response in the proper format\n",
        "                    function_response = {'result': function_result.result}\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"Function call error: {e}\")\n",
        "                    function_response = {'error': str(e)}\n",
        "                \n",
        "                # Add function response to conversation\n",
        "                function_response_part = types.Part.from_function_response(\n",
        "                    name=part.function_call.name,\n",
        "                    response=function_response,\n",
        "                )\n",
        "                function_response_content = types.Content(\n",
        "                    role='tool', \n",
        "                    parts=[function_response_part]\n",
        "                )\n",
        "                contents.append(function_response_content)\n",
        "        \n",
        "        if has_function_calls:\n",
        "            # Generate final response after function calls\n",
        "            final_response = gemini_client.models.generate_content(\n",
        "                model='gemini-1.5-pro',\n",
        "                contents=contents,\n",
        "                config=types.GenerateContentConfig(tools=mcp_server_tools.tools)\n",
        "            )\n",
        "            return final_response.text\n",
        "        else:\n",
        "            # No function calls, return original response\n",
        "            return response.text\n",
        "    else:\n",
        "        return \"No response generated.\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "#### Step 3 - Summarize your favorite video!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "success=True tools=[{'function_declarations': [{'name': 'get_youtube_video_transcript', 'description': \"Retrieve the transcript or video details for a given YouTube video. The 'start' time in the transcript is formatted as MM:SS or HH:MM:SS.\", 'parameters': {'type': 'object', 'properties': {'url': {'type': 'string', 'description': 'The URL of the YouTube video to retrieve the transcript/subtitles for. (e.g. https://www.youtube.com/watch?v=dQw4w9WgXcQ)'}}, 'required': ['url']}}]}] format=<ToolFormat.GEMINI: 'gemini'> error=None\n",
            "response:\n",
            "GenerateContentResponse(\n",
            "    done=True,\n",
            "    iterator=None,\n",
            "    result=protos.GenerateContentResponse({\n",
            "      \"candidates\": [\n",
            "        {\n",
            "          \"content\": {\n",
            "            \"parts\": [\n",
            "              {\n",
            "                \"function_call\": {\n",
            "                  \"name\": \"get_youtube_video_transcript\",\n",
            "                  \"args\": {\n",
            "                    \"url\": \"https://www.youtube.com/watch?v=LCEmiRjPEtQ\"\n",
            "                  }\n",
            "                }\n",
            "              }\n",
            "            ],\n",
            "            \"role\": \"model\"\n",
            "          },\n",
            "          \"finish_reason\": \"STOP\",\n",
            "          \"index\": 0\n",
            "        }\n",
            "      ],\n",
            "      \"usage_metadata\": {\n",
            "        \"prompt_token_count\": 141,\n",
            "        \"candidates_token_count\": 37,\n",
            "        \"total_token_count\": 378\n",
            "      },\n",
            "      \"model_version\": \"gemini-2.5-flash\"\n",
            "    }),\n",
            ")\n",
            "üîß Calling: get_youtube_video_transcript, with args: {'url': 'https://www.youtube.com/watch?v=LCEmiRjPEtQ'}\n",
            "Andrej Karpathy's keynote at AI Startup School on June 17, 2025, discusses the fundamental shift in software development, moving from \"Software 1.0\" to \"Software 3.0.\" He posits that Large Language Models (LLMs) represent a new kind of computer, where natural language, specifically English, becomes the primary programming interface.\n",
            "\n",
            "Here's a summary of the video by chapters:\n",
            "\n",
            "*   **00:00 - Intro**: Introduction to the topic of software evolution.\n",
            "*   **01:25 - Software evolution: From 1.0 to 3.0**: Karpathy elaborates on the historical progression of software, leading up to the current era of Software 3.0.\n",
            "*   **04:40 - Programming in English: Rise of Software 3.0**: This section highlights how natural language is becoming the new way to program, enabling LLMs to perform complex tasks.\n",
            "*   **06:10 - LLMs as utilities, fabs, and operating systems**: Karpathy draws analogies, explaining LLMs' roles similar to utilities, fabrication plants (fabs), and even operating systems, suggesting we are in the early stages of computing, akin to the 1960s.\n",
            "*   **11:04 - The new LLM OS and historical computing analogies**: Further discussion on the concept of an \"LLM OS\" and how historical computing paradigms can help understand this new landscape.\n",
            "*   **14:39 - Psychology of LLMs: People spirits and cognitive quirks**: He describes LLMs as \"people spirits\" or stochastic simulations of people, possessing emergent psychology, superhuman abilities in some areas, but also fallibilities.\n",
            "*   **18:22 - Designing LLM apps with partial autonomy**: Given the nature of LLMs, the focus shifts to designing applications that leverage their \"people spirit\" for partial autonomy.\n",
            "*   **23:40 - The importance of human-AI collaboration loops**: Emphasis on the necessity of effective collaboration between humans and AI for productive outcomes.\n",
            "*   **26:00 - Lessons from Tesla Autopilot & autonomy sliders**: Insights gained from developing Tesla Autopilot are applied to the concept of autonomy in LLM applications, including the idea of \"autonomy sliders.\"\n",
            "*   **27:52 - The Iron Man analogy: Augmentation vs. agents**: An analogy to Iron Man is used to differentiate between AI augmenting human capabilities and AI acting as independent agents.\n",
            "*   **29:06 - Vibe Coding: Everyone is now a programmer**: This part discusses how programming in English makes software development highly accessible, leading to \"vibe coding\" where nearly anyone can contribute.\n",
            "*   **33:39 - Building for agents: Future-ready digital infrastructure**: With LLMs as new primary consumers/manipulators of digital information, there's a call to build digital infrastructure that is ready for agents.\n",
            "*   **38:14 - Summary: We‚Äôre in the 1960s of LLMs ‚Äî time to build**: Karpathy concludes by reiterating that the current state of LLMs is comparable to the 1960s of computing, signifying a nascent but rapidly evolving field, and encouraging development.\n",
            "\n",
            "Overall, the video highlights a significant shift in software, where natural language interfaces and LLMs are creating a new computing paradigm, making software development more accessible and enabling new forms of human-AI collaboration and autonomous applications.\n"
          ]
        }
      ],
      "source": [
        "YOUTUBE_VIDEO_URL = \"https://www.youtube.com/watch?v=LCEmiRjPEtQ\"  # pick a video you like!\n",
        "\n",
        "result = gemini_with_mcp_server(\n",
        "    mcp_server_url=youtube_mcp_instance.server_url, \n",
        "    user_query=f\"Please provide a complete summary of this YouTube video with timestamp: {YOUTUBE_VIDEO_URL}\"\n",
        ")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "‚úÖ Great! You've successfully created an AI agent that uses Gemini's function calling with Klavis MCP servers to summarize YouTube videos!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Case Study 2 : Gemini + Gmail MCP Server (OAuth needed)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üîê Opening OAuth authorization for Gmail, if you are not redirected, please open the following URL in your browser: https://api.klavis.ai/oauth/gmail/authorize?instance_id=d9d482b3-433a-4330-9a8b-9548c0b0a326\n"
          ]
        }
      ],
      "source": [
        "# Create Gmail MCP server instance\n",
        "gmail_mcp_server = klavis_client.mcp_server.create_server_instance(\n",
        "    server_name=McpServerName.GMAIL,\n",
        "    user_id=\"1234\",\n",
        "    platform_name=\"Klavis\",\n",
        "    connection_type=ConnectionType.STREAMABLE_HTTP,\n",
        ")\n",
        "\n",
        "# Handle OAuth authorization\n",
        "if hasattr(gmail_mcp_server, 'oauth_url') and gmail_mcp_server.oauth_url:\n",
        "    webbrowser.open(gmail_mcp_server.oauth_url)\n",
        "    print(f\"üîê Opening OAuth authorization for Gmail: {gmail_mcp_server.oauth_url}\")\n",
        "    print(\"Please complete the OAuth authorization in your browser...\")\n",
        "    input(\"Press Enter after completing OAuth authorization...\")\n",
        "else:\n",
        "    print(\"‚úÖ No OAuth required for this server instance\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "EMAIL_RECIPIENT = \"zihaolin@klavis.ai\" # Replace with your email\n",
        "EMAIL_SUBJECT = \"Test Gemini + Gmail MCP Server\"\n",
        "EMAIL_BODY = \"Hello World from Gemini!\"\n",
        "\n",
        "result = gemini_with_mcp_server(\n",
        "    mcp_server_url=gmail_mcp_server.server_url, \n",
        "    user_query=f\"Please send an email to {EMAIL_RECIPIENT} with subject {EMAIL_SUBJECT} and body {EMAIL_BODY}\"\n",
        ")\n",
        "\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary\n",
        "\n",
        "This tutorial demonstrated how to integrate Google's Gemini with function calling capabilities with Klavis MCP servers to create powerful AI applications. We covered practical examples and interactive features:\n",
        "\n",
        "**üé• YouTube Integration**: Built an AI assistant that can automatically summarize YouTube videos by extracting transcripts and providing detailed, timestamped summaries.\n",
        "\n",
        "**üìß Gmail Integration**: Created an AI-powered email assistant that can send emails through Gmail with OAuth authentication.\n",
        "\n",
        "**üí¨ Interactive Chat**: Added multi-turn conversation capabilities that maintain context across interactions.\n",
        "\n",
        "### Key Takeaways:\n",
        "- **Modern API**: Uses the latest `google-genai` library with improved type safety and performance\n",
        "- **Easy Setup**: Klavis MCP servers can be created with just a few lines of code\n",
        "- **Robust Function Calling**: Better error handling and response management\n",
        "- **Conversation Context**: Maintains state across multiple interactions\n",
        "- **Versatile**: Support for both simple APIs (YouTube) and OAuth-authenticated services (Gmail)\n",
        "- **Scalable**: The same pattern can be applied to any of the MCP servers available in Klavis\n",
        "- **Developer Friendly**: Enhanced logging and debugging capabilities\n",
        "\n",
        "### Next Steps:\n",
        "- Try different MCP servers from Klavis (Notion, Slack, Airtable, etc.)\n",
        "- Experiment with multi-modal capabilities using images and files\n",
        "- Build more complex workflows with multiple function calls\n",
        "- Integrate with your own applications and use cases\n",
        "\n",
        "**Happy building!** üöÄ\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
